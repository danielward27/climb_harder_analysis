{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "The survey data is very messy and requires cleaning. A lot of questions were \"open-ended\", and users often formatted their responses differently, for example using different units. This notebook cleans the messy survey data, so that it can be easily analysed (see analysis.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "All imports are included here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"C:/Users/Danie/OneDrive/Documents/jupyter_notebooks/climb_harder_analysis/climbharder_survey.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "#### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "colname_dict = {\n",
    "    \"Timestamp\": \"timestamp\",\n",
    "    \"Sex\": \"sex\",\n",
    "    \"Height (cm)\": \"height_cm\",\n",
    "    \"Weight (KG)\": \"weight_kg\",\n",
    "    \"Arm Span (cm)\": \"arm_span_cm\",\n",
    "    \"How long have you been climbing for?\": \"climbing_years\",\n",
    "    \"Where do you climb?\": \"indoor_outdoor\",\n",
    "    \"Hardest V Grade ever climbed \": \"max_boulder_grade\",\n",
    "    \"Hardest V Grade climbed in the Last 3 months\": \"max_boulder_grade_last_3_months\",\n",
    "    \"The V grade you can send 90-100% of routes \": \"consistently_send_boulder_grade\",\n",
    "    \"Hardest Route grade climbed (Ewbank grade) \": \"max_route_grade\",\n",
    "    \"Hardest route climbed last 3 months (ewbank)\": \"max_route_grade_last_3_months\",\n",
    "    \"Route grade you can send 90-100% of climbs\": \"consistently_send_route_grade\",\n",
    "    \"Frequency of climbing sessions per week\": \"climbing_frequency\",\n",
    "    \"Average hours climbing per week (not including training)\": \"climbing_hours\",\n",
    "    \"Average hours Training for climbing per week \": \"training_hours\",\n",
    "    \"Hangboard Frequency per week \": \"hangboard_frequency\",\n",
    "    \"Hangboard grips used \": \"hangboard_grips_trained\",\n",
    "    \"Style of Hangboarding chosen \": \"hangboarding_style\",\n",
    "    \"Max Weight hangboard 18mm edge - Half crimp (KG)  (10 seconds) (added weight only)\": \"max_18_mm_hang_half_crimp_kg\",\n",
    "    \"Max Weight hangboard 18mm edge - open crimp (KG) (10 seconds)  (added weight only)\": \"max_18_mm_hang_open_crimp_kg\",\n",
    "    \"Min Edge used (mm, +kg if weight added ) - Half Crimp (10 seconds)\": \"min_edge_half_crimp_mm\",\n",
    "    \"Min Edge used (mm, +kg if weight added) - Open crimp (10 seconds) \": \"min_edge_open_crimp_mm\",\n",
    "    \"Campus Board frequency per week \": \"campus_frequency\",\n",
    "    \"Campus Board time per week (hours)\": \"campus_hours\",\n",
    "    \"Frequency of Endurance training sesions per week\": \"endurance_frequency\",\n",
    "    \"Endurance training \": \"endurance_style\",\n",
    "    \"General Strength Training frequency per week \": \"general_stength_frequency\",\n",
    "    \"Time spent General strength training (hours)\": \"general_strength_hours\",\n",
    "    \"Type of Strength training\": \"general_strength_style\",\n",
    "    \"Other activities (ie yoga, cardio)\": \"other_training\",\n",
    "    \"Max pull up reps\": \"max_pull_ups\",\n",
    "    \"5 rep max weighted pull ups\": \"pull_up_5_rep_max_kg\",\n",
    "    \"max push ups reps\": \"max_push_ups\",\n",
    "    \"max L-sit time \": \"max_l_sit_s\",\n",
    "}\n",
    "\n",
    "df = df.rename(columns = colname_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing typos, and forcing consistent formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sex\"] = df[\"sex\"] == \"Male\"  # Males == 1/True, Females == 0/False\n",
    "\n",
    "# Clean height_cm\n",
    "df[\"height_cm\"] = df[\"height_cm\"].replace(\"5 ft 8inches. Im amurican i dont know what centimeters are\", 173) # Help the confused American.\n",
    "df[\"height_cm\"] = df[\"height_cm\"].replace(\"cm\", \"\", regex = True).astype(str).str.strip()\n",
    "df[\"height_cm\"] = df[\"height_cm\"].astype(float)\n",
    "\n",
    "# Clean weight_kg\n",
    "replacements_dict = {\"135 pounds....so....65 kg?\": 61, \"82,5\": 83, \"51-53...\": 52, \"~55\": 55} # The same confused American\n",
    "df[\"weight_kg\"] = df[\"weight_kg\"].replace(replacements_dict)\n",
    "df[\"weight_kg\"] = df[\"weight_kg\"].replace(\"kg\", \"\", regex = True).astype(str).str.strip()\n",
    "df[\"weight_kg\"] = df[\"weight_kg\"].astype(float)\n",
    "\n",
    "# Clean arm_span_cm\n",
    "replacements_dict = {\"161??\": 161, \"5 ft 10 inches\": 178}\n",
    "df[\"arm_span_cm\"] = df[\"arm_span_cm\"].replace(replacements_dict)\n",
    "df[\"arm_span_cm\"] = df[\"arm_span_cm\"].replace([\"-\", \"Dont know\", \"no idea\", \"?\", \"Not sure\", \"don't know\", # Probably better to use an explicit list rather than extracting using isnumeric() == False,\n",
    "                                             \"unknown\", \"Unknown\", \"???\", \"**\", \"idk\", \"dunno\", \"Don't know\"], np.nan)  # as it\"s better to throw an error than accidentally convert data that could be useful to np.nan.\n",
    "df[\"arm_span_cm\"] = df[\"arm_span_cm\"].replace(\"cm\", \"\", regex = True).astype(str).str.strip()\n",
    "\n",
    "# Clean climbing_years\n",
    "df[\"climbing_years\"] = df[\"climbing_years\"].str.rstrip(\" years\")\n",
    "df[\"climbing_years\"] = df[\"climbing_years\"].replace(\"More than 15\", \"15.25\") # Set >15 to 15.25 (not ideal, but sensible)\n",
    "df[\"climbing_years\"] = df[\"climbing_years\"].apply(lambda x: np.array(x.split(\" - \")).astype(float).mean()) # Lots of categories so makes sense to handle as a regression problem using the midpoint\n",
    "\n",
    "# Strip leading V in V grades and add np.nan for those that don't boulder\n",
    "for col in [\"max_boulder_grade\", \"max_boulder_grade_last_3_months\", \"consistently_send_boulder_grade\"]:\n",
    "    df[col] = df[col].str.lstrip(\"V\")\n",
    "    df[col] = df[col].replace(\"I don't boulder\", np.nan)\n",
    "    df[col] = pd.to_numeric(df[col]).astype(\"Int32\")\n",
    "    \n",
    "# Add np.nan for those that don't route climb\n",
    "for col in [\"max_route_grade\", \"max_route_grade_last_3_months\", \"consistently_send_route_grade\"]:\n",
    "    df[col] = df[col].replace(\"I don't climb routes\", np.nan)\n",
    "    df[col] = pd.to_numeric(df[col]).astype(\"Int32\")\n",
    "    \n",
    "# Deal with messy max pull ups data\n",
    "replacements_dict = {\n",
    "    \">20\": 20, \"12?  I don't work on bodyweight pullups for reps.\": 12,\n",
    "    \"3 x 8\": 8, \"15-20\": 18, \"20?\": 20, \"maybe 5\": 5, \"15?\": 15,\n",
    "    \"5, maybe, not sure\": 5,\"15+\": 15, \"Not sure... probably 12-15?\": 14,\n",
    "    \"approx 25\": 25, \"20+\": 20, \"25ish\": 25, \"8-12\": 10, \"7?? \": 7}\n",
    "\n",
    "df['max_pull_ups'] = df['max_pull_ups'].replace(replacements_dict)\n",
    "df.loc[df['max_pull_ups'].str.isnumeric() == False, 'max_pull_ups'] = np.nan\n",
    "\n",
    "# Lots of missing cases (and a measure of strength not a training technique, so less interested)\n",
    "df = df.drop(columns=[\"max_18_mm_hang_half_crimp_kg\", \"max_18_mm_hang_open_crimp_kg\", \"min_edge_half_crimp_mm\",\n",
    "                      \"min_edge_open_crimp_mm\", \"pull_up_5_rep_max_kg\", \"max_push_ups\", \"max_l_sit_s\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract some basic features\n",
    "A few columns are comma seperated strings of training activities each individual does. We'll make a function to extract this into seperate columns for each activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comma_sep_to_bool_cols(df, col_to_split, check_string_contains):\n",
    "    \"\"\"Takes column with comma seperated strings, checks the strings for items in check_string_contains list.\n",
    "    converts column into multiple bool columns with colnames extracted from check_string_contains.\"\"\"\n",
    "    df=df.copy() # Small dataset so not worried about speed hit\n",
    "    col_names_list = [\"trains_{}\".format(i.lower().replace(\" \", \"_\")) for i in check_string_contains]\n",
    "    for colname, string in zip(col_names_list, check_string_contains):\n",
    "        df[colname] = col_to_split.str.contains(string)\n",
    "    df = df.drop(columns=col_to_split.name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate out csv columns to booleans\n",
    "grip_list = [\"Full Crimp\", \"Half Crimp\", \"Open Crimp\", \"Front 3\", \"Back 3\", \"Front 2\", \"Middle 2\", \"Back 2\", \"Slopers\", \"Pinch\", \"Monos\"]\n",
    "df = comma_sep_to_bool_cols(df, df[\"hangboard_grips_trained\"], grip_list)\n",
    "\n",
    "hangboarding_style = [\"Repeaters\", \"Max weight\", \"Min Edge\", \"One arm hang\", 'no hangs', \"Other protocol\"]\n",
    "df = comma_sep_to_bool_cols(df, df['hangboarding_style'], hangboarding_style)\n",
    "\n",
    "df[\"endurance_style\"] = df[\"endurance_style\"].fillna(\"None\") # Assume those that didn't answer did no training\n",
    "endurance_style = [\"Laps of routes\", \"4x4\", \"ARC\", \"systems boards\", \"max moves\", \"route climbing intervals\", \"threshold intervals\"]\n",
    "df = comma_sep_to_bool_cols(df, df[\"endurance_style\"], endurance_style)\n",
    "\n",
    "strength_style = [\"Antagonists\", \"Legs\", \"Core\", \"Upper body pulling\", \"Upper body pushing\"]\n",
    "df = comma_sep_to_bool_cols(df, df[\"general_strength_style\"], strength_style)\n",
    "\n",
    "# Convert indoor_outdoor into two booleans: climbs_indoors and climbs_outdoors\n",
    "df[\"climbs_indoors\"] = (df[\"indoor_outdoor\"] == \"Indoor and outdoor climbing\") | (df[\"indoor_outdoor\"] == \"Indoor Climbing only\")\n",
    "df[\"climbs_outdoors\"] = (df[\"indoor_outdoor\"] == \"Indoor and outdoor climbing\") | (df[\"indoor_outdoor\"] == \"Outdoor Climbing only\")\n",
    "df = df.drop(columns = \"indoor_outdoor\")\n",
    "\n",
    "# Extract whether someone consistently said they bouldered\n",
    "boulders_bool_df = df[[\"max_boulder_grade\", \"max_boulder_grade_last_3_months\", \"consistently_send_boulder_grade\"]] != \"I don't boulder\"\n",
    "df[\"boulders\"] = boulders_bool_df.all(axis=\"columns\")\n",
    "    \n",
    "# Extract whether someone consistently said they route climbed\n",
    "routes_bool_df = df[[\"max_route_grade\", \"max_route_grade_last_3_months\", \"consistently_send_route_grade\"]] != \"I don't climb routes\"\n",
    "route_climbs = routes_bool_df.all(axis=\"columns\")\n",
    "df[\"route_climbs\"] = route_climbs\n",
    "\n",
    "# other_training had open answers, we'll extract some of the most common ones into cardio and yoga\n",
    "df['other_training'] = df['other_training'].str.lower()\n",
    "df['other_training'] = df['other_training'].fillna(\"None\")  # Assume those that didn't answer did no other activities\n",
    "df['other_training'] = df['other_training'].replace(\"n/a\", \"None\")\n",
    "df['cardio'] = df['other_training'].str.contains(\"cardio|jogging|cycling|running|soccer|mountain biking|bike|badminton\", regex=True, na=False)\n",
    "df['yoga'] = df['other_training'].str.contains(\"yoga|stretch\", regex=True, na=False)\n",
    "df = df.drop(columns = \"other_training\")\n",
    "\n",
    "# Typos and wrong units\n",
    "df[\"height_cm\"] = df[\"height_cm\"].replace({1.67:167, 1.68:168}) # Answered in meters rather than cm.\n",
    "df[\"arm_span_cm\"] = df[\"arm_span_cm\"].astype(float)\n",
    "df[\"height_cm\"] = df[\"height_cm\"].replace(62, df.loc[df['height_cm'] == 62.0, 'arm_span_cm']) # Had reasonable arm span to fill data\n",
    "df[\"height_cm\"] = df[\"height_cm\"].replace(1295, df[\"height_cm\"].mean()) # Not sure what units this person was using. We'll fill the height with the mean.\n",
    "df[\"arm_span_cm\"] = df[\"arm_span_cm\"].replace(1.68, 168) # Answered in meters\n",
    "\n",
    "# Some people clearly measured arm span wrong (perhaps measuring one arm)\n",
    "bool_list = abs(df[\"height_cm\"].astype(float) - df[\"arm_span_cm\"].astype(float)) > 50\n",
    "df.loc[bool_list, \"arm_span_cm\"] = np.nan\n",
    "\n",
    "# Some people definitely measured weight in pounds unfortunately. We'll try and correct for this.\n",
    "df[\"weight_kg\"] = df[\"weight_kg\"].apply(lambda x: x if x <120 else x / 2.20462)\n",
    "\n",
    "# Not interested in following variables, I want to predict max bouldering ability from training strategy, height and sex etc. factors.\n",
    "df = df.drop(columns= [\"timestamp\", \"max_route_grade\", \"max_route_grade_last_3_months\", \"consistently_send_route_grade\",\n",
    "                       \"max_boulder_grade_last_3_months\", \"consistently_send_boulder_grade\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_data.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
